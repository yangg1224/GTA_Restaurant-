---
title: "TITLE"
author: "Adrian Wong, Yingying Zhou, Xinyi Xu, Yang Wu "
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
 bookdown::pdf_document2:
 toc: no
subtitle: "SUBTITLE"
abstract: "ABSTRACT"
thanks: 'Code and data are available at: https://github.com/yangg1224/groupproject-.git'
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
#install.packages("PerformanceAnalytics")
library("PerformanceAnalytics")
library(ggplot2)
library(kableExtra)

```

# Introduction
```{r}

```

# Data 

## Intervention 

## Data Gathering Method 

## Descriptive Analysis
```{r read_data, include=FALSE}

setwd("~/Downloads/Git/groupproject-") 

# read raw dataset from scripts, need to run survey_response _simulation first.
simulated_data<- read_csv("inputs/simulated_data.csv") 

# We add a new column To distinguish the restaurant size by employees number. 
# if employees number >20 then we define it is big, otherwise it is small.
for (i in 1:nrow(simulated_data)){
  if ((simulated_data$Q8[i] == ">30") || (simulated_data$Q8[i] == "20-30")){
  simulated_data$size[i] = "Big"  
  }else {
    simulated_data$size[i] = "Small"
  }
}

treated_data<-
  filter(simulated_data, simulated_data$type == "Treated" ) # load treated data 

control_data<-
  filter(simulated_data, simulated_data$type == "Control" ) # load control data
```

```{r size,echo=FALSE}
# Get the number of rows
size<- nrow(simulated_data)
```

After discussing data gathering method, we sampled data in R [@citeR]. We totally have **`r size`** observations, and 14 of following features according to the questionnaires.

* `type` : Categorical identifier [“Treated” or “Control”] for each observation 
* `Q1` : First three digitals of the postcode 
* `Q2` : Categorical identifier for distinguishing the type of restaurants 
* `Q3` : Region name in GTA
* `Q4` : Describe whether the restaurant is a franchise (“Franchise” or “No”)
* `Q5` : The length of the operation years for each restaurant 
* `Q6` : Describe whether the restaurant offer takeout service (“Yes” or “No”)
* `Q7` : Describe whether the restaurant offer delivery service (“Yes” or “No”)
* `Q8` : Number of employees in the restaurant (category type)
* `Q9` : Average employee hourly rate (CAD) 
* `Q10` : Describe whether the restaurant has been a site of a potential COVID case (“Yes” or “No”)
* `Q11` : Describe the restaurant’s fixed costs change situation 
* `Q12` :  Describe the restaurant’s flexible costs change situation 
* `Q13` : The restaurant’s past month revenue (CAD)

The first six rows of raw data is shown in the table1 below. (Table \@ref(tab:rowdata))
```{r rowdata, echo=FALSE}
#plot row data set in table
  head(simulated_data,10)%>%
  select(-size)%>%
  kableExtra::kbl(caption = "First 6 rows Raw data ") %>%
  kableExtra::kable_styling(latex_options = "scale_down")%>% # use scale_down option to make the font
  kable_styling()
```

### Revenue distributions group by restaurant size
```{r revenue_distribution, echo=FALSE}


library(ggplot2)
library(ggthemes)
# Treated group
rd1<-
  ggplot(treated_data, aes(x = treated_data$Q13)) +
  geom_histogram(aes(color = size, fill= size),
                position = "identity", bins = 30, alpha=0.5) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))+
  labs(title="Revenue Distributions in Treated Group", x="Renvenue", y="Count")+
  geom_density(alpha=.2, fill="#FF6666")+
  theme_calc()
# Control group
rd2<-
  ggplot(control_data, aes(x = control_data$Q13)) +
  geom_histogram(aes(color = size, fill= size),
                position = "identity", bins = 30, alpha=0.5) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))+
  labs(title="Revenue Distributions in Control Group", x="Renvenue", y="Count")+
  geom_density(alpha=.2, fill="#FF6666")+
  theme_calc()
# combine two diagram in one graph
#install.packages("ggpubr")
library(ggpubr)
ggarrange(
  rd1, rd2, 
  ncol = 1, nrow = 2,
  heights = c(1, 1),
  align = "hv",
  common.legend = TRUE, legend = "bottom"
  )

```

### restaurant type by regions

```{r restaurant_type, echo=FALSE,fig.width=12, fig.height=4}

library(viridis)


# Treated group
rt1<-
  ggplot(treated_data, aes(fill= Q3, x= Q2)) +
  geom_bar(position="stack", stat="count")+
    ggtitle("Treated Group: Restaurant Types") +
    xlab("Regions")+
    ylab("Count of Numbers")+
    theme_grey()

    
rt1<- rt1 + guides(fill=guide_legend(title="Types")) # change the Legend title 

# Control group
rt2<-
  ggplot(control_data, aes(fill= Q3, x= Q2)) +
  geom_bar(position="stack", stat="count")+
    ggtitle("Control Group: Restaurant Types") +
    xlab("Regions")+
    ylab("Count of Numbers")+
    theme_grey()
    
rt2<- rt2 + guides(fill=guide_legend(title="Types")) # change the Legend title 
# combine two diagram in one graph
ggarrange(
  rt1, rt2, 
  ncol = 2, nrow = 1,
  vjust = 1,
  widths = c(2, 2),
  align = "hv",
  common.legend = TRUE, legend = "bottom"
  )

```


### Flex and fiexed cost changes 

```{r felx_fix, echo=FALSE, fig.width=10, fig.height=4}



# Treated group

# Fixed costs 
fixc1<-
  ggplot(treated_data, aes(fill= Q11, x=Q11)) +
  geom_bar(stat="count", width = 0.5)+
    ggtitle("Fixed costs changes") +
    coord_flip()+
    xlab("Changes")+
    ylab("Number of restaurants")+
    theme_minimal()

fixc1<- fixc1 + guides(fill=guide_legend(title="Changes")) # change the Legend title 

# flex cost
flexc1<-
    ggplot(treated_data, aes(fill= Q12, x=Q12)) +
    geom_bar(stat="count", width = 0.5)+
    ggtitle("Treated Group: Flexible costs changes") +
    coord_flip()+
    xlab("Changes")+
    ylab("Number of restaurants")+
    theme_minimal()


flexc1<- flexc1 + guides(fill=guide_legend(title="Changes")) # change the Legend title 

# Control group
fixc2<-
  ggplot(control_data, aes(fill= Q11, x=Q11)) +
  geom_bar(stat="count", width = 0.5)+
    ggtitle("Fixed costs changes") +
    coord_flip()+
    xlab("Changes")+
    ylab("Number of restaurants")+
    theme_minimal()

fixc2<- fixc2 + guides(fill=guide_legend(title="Changes")) # change the Legend title 

# flex cost
flexc2<-
    ggplot(control_data, aes(fill= Q12, x=Q12)) +
    geom_bar(stat="count", width = 0.5)+
    ggtitle("Control Group: Flexible costs changes") +
    coord_flip()+
    xlab("Changes")+
    ylab("Number of restaurants")+
    theme_minimal()


flexc2<- flexc2 + guides(fill=guide_legend(title="Changes")) # change the Legend title 



# combine two diagram in one graph
ggarrange(
  flexc1,fixc1,flexc2, fixc2,
  ncol = 2, nrow = 2,
  vjust = 1,
  widths = c(2, 2),
  align = "hv",
  common.legend = TRUE, legend = "bottom"
  )

```

### Distribution average employee salary
```{r salary_distribution, echo=FALSE, fig.width=10, fig.height=4}
library(ggthemes)
# Treated group
s1<-
  ggplot(treated_data, aes(x = Q2, y= Q9)) +
  geom_boxplot(outlier.colour="red", 
               outlier.shape=5,
               outlier.size=4) +
  labs(title="Salary Distributions in Treated Group", x="Regions", y="Hourly rate")+
  geom_dotplot(binaxis='y', stackdir='center', dotsize=0.01)+ # add dots
  theme_economist()

# Control group
s2<-
  ggplot(control_data, aes(x = Q2, y= Q9)) +
  geom_boxplot(outlier.colour="red", 
               outlier.shape=5,
               outlier.size=4) +
  labs(title="Salary Distributions in Control Group", x="Regions", y="Hourly rate")+
  geom_dotplot(binaxis='y', stackdir='center', dotsize=0.01)+ #add dots
  theme_economist()


# combine two diagram in one graph

library(ggpubr)
ggarrange(
  s1, s2, 
  ncol = 2, nrow = 1,
  hjust = -0.5,
  align = "hv"
  )

```

### correlation matrix
```{r correlation, echo=FALSE, fig.width=20, fig.height=20}
#install.packages("fastDummies")
library(fastDummies)
Dummy_data<-simulated_data[-c(1,2,10)]

Dummy_data<- fastDummies::dummy_cols(Dummy_data)

# correlation matrix for Big restaurants
Dummy_data<-Dummy_data[-c(1:3,5:10,12,43)]


# Compute a correlation matrix
corr <- round(cor(Dummy_data), 1)

# Compute a matrix of correlation p-values
#install.packages("ggcorrplot")
library(ggcorrplot)
p.mat <- cor_pmat(Dummy_data)

# Visualize the lower triangle of the correlation matrix
# Barring the no significant coefficient
corr.plot1 <- ggcorrplot(
  corr, hc.order = TRUE, type = "lower",
  p.mat=p.mat
  )
corr.plot1

# correlation matrix for Small restaurants
Dummy_data<-simulated_data[-c(1,2,10)]
Dummy_data<- fastDummies::dummy_cols(Dummy_data)
Dummy_data<-Dummy_data[-c(1:3,5:10,12,42)]


# Compute a correlation matrix
corr <- round(cor(Dummy_data), 1)

# Compute a matrix of correlation p-values
library(ggcorrplot)
p.mat <- cor_pmat(Dummy_data)

# Visualize the lower triangle of the correlation matrix
# Barring the no significant coefficient
corr.plot2 <- ggcorrplot(
  corr, hc.order = TRUE, type = "lower",
  p.mat=p.mat
  )
corr.plot2


# combine two diagram in one graph

ggarrange(
  corr.plot1, corr.plot2, 
  labels = c('Big restaurant', 'Small restaurant'),
  ncol = 2, nrow = 1,
  align = "hv"
  )

```

# Discussion

## Overview 

## Findings 

### Finding ONE

### Finding TWO

### Finding THREE

## Limitation

## Future Directions 

```{r}

```

\newpage
# Appendix

## Appendix A
```{r AppendixA, message=FALSE, echo = FALSE}
### Number in GTA ### 
number_of_Toronto = 7500
number_of_Durham = 3260
number_of_York = 5553
number_of_Peel = 6235
number_of_Halton = 2803
number_of_GTA = sum(number_of_Toronto,number_of_Durham,number_of_York,number_of_Peel,number_of_Halton)

### Proportion ###
proportion_Toronto = (number_of_Toronto/number_of_GTA*100) 
proportion_Durham = (number_of_Durham/number_of_GTA*100)
proportion_York = (number_of_York/number_of_GTA*100)
proportion_Peel = (number_of_Peel/number_of_GTA*100)
proportion_Halton = (number_of_Halton/number_of_GTA*100)
Proportion_GTA = (number_of_GTA /number_of_GTA*100)

### Number of Sample ###
number_of_sample = 1637

sample_Toronto =proportion_Toronto*number_of_sample
sample_Durham =proportion_Durham *number_of_sample
sample_York =proportion_York*number_of_sample
sample_Peel =proportion_Peel*number_of_sample
sample_Halton =proportion_Halton *number_of_sample

### Dataframe ###
sample_size <- data.frame(
  Region = c ("Toronto", "Durham" , "York" , "Peel" , "Halton","Total"),
  Number_of_Region = c (number_of_Toronto,number_of_Durham,number_of_York,number_of_Peel,number_of_Halton,number_of_GTA),
  Proportion_of_Region= c (proportion_Toronto,proportion_Durham,proportion_York,proportion_Peel,proportion_Halton,Proportion_GTA)%>% round(digits = 2),
  Sample_of_Region = c (sample_Toronto,sample_Durham,sample_York ,sample_Peel,sample_Halton,number_of_sample) %>% round(digits = 0)
  )
  
### Table ###
library(kableExtra)
sample_size %>% 
  knitr::kable(caption = "Detailed information for stratification",
               col.names = c("Region", "Number of Restuarants", "Proportion(%)", "Sample Selected"))%>%
  kable_styling()
```

## Appendix B
```{r AppendixB, message=FALSE, echo = FALSE}
### basic information ###
number_of_survey = 3454
number_of_consent = 11325

print_cost_per_page = 0.05 
envelope_cost = 0.15
one_way_stamp = 0.55

### Calculation ###

total_print_cost = print_cost_per_page* (number_of_consent+number_of_survey)
total_envelope_cost = (number_of_consent+number_of_survey)*envelope_cost*2
total_stamp_cost =(number_of_consent+number_of_survey)*one_way_stamp*2

total_cost = total_print_cost+total_envelope_cost+total_stamp_cost

### dataframe ###
estimated_cost <- data.frame(
  Components = c ("Printing Cost", "Envelope Cost", "Stamp Cost"),
  Cost_per_unit= c (print_cost_per_page,envelope_cost,one_way_stamp),
  Total_cost_of_each_component  = c (total_print_cost, total_envelope_cost, total_stamp_cost)
)

### Table  ###
library(kableExtra)
estimated_cost %>% 
  knitr::kable(caption = "Estimated Cost",
               col.names = c("Components", "Cost per unit", "Total cost for each component"))%>%
  kable_styling()


```



\newpage

# References
